<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <meta name="author" content="Andi Gu" />
      <meta name="dcterms.date" content="2022-06-28" />
      <meta name="keywords" content="geometric algebra, notes,
physics" />
      <meta name="description" content="Geometric algebra notes from the Geometric Algebra for Physicists textbook." />
  
  <link rel="author" href="https://scholar.google.com/citations?user=XGTtMs8AAAAJ" />

  <title>Geometric Algebra</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: blue!50!black;
    }
    a:visited {
      color: blue!50!black;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
    <link rel="stylesheet" href="/static/css/index.css" />
      
    
    
    
    
    
    <style>
    .statement.plain {
    	font-style: italic;
    }
    .statement.plain .statement-label {
    	font-style: normal; font-weight: normal; font-variant: normal; font-weight: bold;
    }
    .statement.plain .statement-spah {
    	word-spacing: 1em;
    }
    .statement.plain .statement-info {
    	font-style: normal; font-weight: normal; font-variant: normal;
    }
    </style>
    <style>
    .statement.proof {
    	font-style: normal; font-weight: normal; font-variant:normal;
    }
    .statement.proof .statement-label {
    	font-style: normal; font-weight: normal; font-variant: normal; font-style: italic;
    }
    .statement.proof .statement-spah {
    	word-spacing: 1em;
    }
    .statement.proof .statement-info {
    	font-style: normal; font-weight: normal; font-variant: normal;
    }
    </style>
  
  <script>
    window.MathJax = {
      loader: { load: ['[tex]/physics', '[tex]/mathtools'] },
      tex: { packages: { '[+]': ['physics', 'mathtools'] } }
    };

  </script>

    <script
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
    type="text/javascript"></script>
    <script type="module" src="/static/js/js.cookie.min.js"></script>
  <script src="https://kit.fontawesome.com/de9cc10f80.js" crossorigin="anonymous"></script>

  <script src="/static/js/script.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GKD85BYZJD"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-GKD85BYZJD');
  </script>

</head>

<body>
  
  <div class="container">

    <div class="nav-container">
      <nav class="navbar">
        <a href="/" class="nav-link" id="nav-home">Home</a>
        <a href="/notes" class="nav-link" id="nav-notes">Notes</a>
      </nav>
    </div>

    <div class="content-container">
            <header id="title-block-header">
        <h1 class="title">Geometric Algebra</h1>
                        <p class="author">Andi Gu</p>
        
              </header>
                  <nav id="TOC" role="doc-toc">
                <h2 id="toc-title">Table of Contents</h2>
                <ul>
                <li><a href="#foundations" id="toc-foundations"><span
                class="toc-section-number">1</span> Foundations</a>
                <ul>
                <li><a href="#properties-of-the-geometric-product"
                id="toc-properties-of-the-geometric-product"><span
                class="toc-section-number">1.1</span> Properties of the
                Geometric Product</a></li>
                </ul></li>
                <li><a href="#bibliography"
                id="toc-bibliography">References</a></li>
                </ul>
      </nav>
            <p>This is a collection of notes from my study of the
            <em>Geometric Algebra for Physicists</em> textbook <span
            class="citation" data-cites="doran2007">(<a
            href="#ref-doran2007" role="doc-biblioref">Doran and Lasenby
            2007</a>)</span>.</p>
            <h1 data-number="1" id="foundations"><span
            class="header-section-number">1</span> Foundations</h1>
            <p>The entire structure of geometric algebra can be boiled
            down to the geometric product, which is a binary operation
            between two vectors <span class="math inline">\(a\)</span>
            and <span class="math inline">\(b\)</span>. The usual rules
            of a vector space apply to these vectors, and the usefulness
            of geometric algebra is in the structure revealed by the
            product <span class="math inline">\(ab\)</span>. This
            product satisfies three fairly natural axioms.</p>
            <ol type="1">
            <li>It is associative: <span
            class="math inline">\((ab)c=a(bc)\)</span></li>
            <li>It distributes over addition: <span
            class="math inline">\(a(b+c)=ab+ac\)</span></li>
            <li>The square of any vector is real: <span
            class="math inline">\(a^2 \in \mathbb{R}\)</span>. We do not
            make the assumption that <span class="math inline">\(a^2
            \geq 0\)</span> to allow for the possibility of spaces with
            mixed signature (e.g., Minkowski space).</li>
            </ol>
            <p>It is important not to interpret this product <span
            class="math inline">\(uv\)</span> as another vector. In
            fact, <span class="math inline">\(uv\)</span> is a sum of a
            scalar element <span class="math inline">\(u \in
            \mathbb{R}\)</span> and a ‘bivector’ <span
            class="math inline">\(V\)</span>: <span
            class="math inline">\(ab=u + V\)</span> – this should be
            understood as something like a complex number <span
            class="math inline">\(u+iv\)</span>. In fact, for a vector
            space of dimension 2, this analogy is exact. In general, the
            bivector should be pictured as a directed area, or an object
            like the angular momentum in classical mechanics. This
            analogy extends further: we can have a trivector, which is
            an oriented volume, and so on and so forth.</p>
            <p>However, this geometric product is not so exotic. We can
            still understand it in terms of some familiar concepts. For
            one, we observe that <span
            class="math inline">\((a+b)^2\)</span> is always real, so we
            must have <span class="math inline">\(a^2+ab+ba+b^2 \in
            \mathbb{R} \implies ab + ba \in \mathbb{R}\)</span>. We have
            found that the symmeterized geometric product is a binary
            relation between vectors that outputs a real number – that
            is, a dot product! So we define <span
            class="math display">\[a \cdot b =
            \frac{(ab+ba)}{2}.\]</span> We define the remaining part of
            the product as the exterior product (which might be thought
            of as replacing the role of the cross product): <span
            class="math display">\[a \wedge b =
            \frac{ab-ba}{2}.\]</span> This then gives <span
            class="math inline">\(ab=a \cdot b + a \wedge b\)</span>: a
            sum of a scalar and a bivector, as promised.</p>
            <p>Well, technically, not yet: we do not have a good reason
            to believe we should understand <span
            class="math inline">\(a \wedge b\)</span> as a bivector (or
            a directed area) yet. So we define it as such, and show this
            definition conforms to our intuition later. More precisely,
            we define exterior product of <span
            class="math inline">\(r\)</span> vectors as the full
            anti-symmeterized product over all of them: <span
            class="math display">\[a_1 \wedge a_2 \wedge \ldots \wedge
            a_r = \frac{1}{r!}\sum_{\sigma \in \mathbb{S}_r}
            (-1)^{\sigma} a_{\sigma(1)} a_{\sigma(2)} \ldots
            a_{\sigma(r)},\]</span> where <span
            class="math inline">\(\mathbb{S}_r\)</span> is the set of
            all permutations on <span class="math inline">\(r\)</span>
            elements and <span
            class="math inline">\((-1)^\sigma\)</span> is the sign of a
            permutation. A consequence of this definition is that the
            product reverses sign under exchange of any two vectors.
            Then, we see that if any vector is repeated, the exterior
            product must be zero, which then implies if the vectors are
            linearly dependent, the exterior product is also zero (this
            follows simply by distributivity of the geometric product
            under addition). Therefore, the outer product can be
            understood to measure the dimensionality of a set of
            vectors. We say that the outer product of <span
            class="math inline">\(r\)</span> vectors has grade <span
            class="math inline">\(r\)</span> (if it does not vanish). A
            multivector that can be written purely as an outer product
            is called a blade.</p>
            <div id="blade-product" class="statement lemma plain">
            <p><span class="statement-heading"><span
            class="statement-label">Lemma 1</span>.</span><span
            class="statement-spah"> </span>Any blade <span
            class="math inline">\(a_1 \wedge \ldots \wedge a_r\)</span>
            can be written simply as a product of orthogonal vectors
            <span class="math inline">\(e_1 \ldots e_r\)</span>. This
            justifies our idea that a blade with <span
            class="math inline">\(r\)</span> vectors can be interpreted
            as a directed area for <span
            class="math inline">\(r=2\)</span>, volume for <span
            class="math inline">\(r=3\)</span>, and so on.</p>
            </div>
            <div class="statement proof proof unnumbered">
            <p><span class="statement-heading"><span
            class="statement-label">Proof</span>.</span><span
            class="statement-spah"> </span>Let <span
            class="math inline">\(A_{i,j}=a_i \cdot a_j\)</span>. Since
            <span class="math inline">\(A_{i,j}\)</span> is a symmetric
            matrix, it can be diagonalized with <span
            class="math inline">\(P^T D P\)</span>, where <span
            class="math inline">\(P\)</span> is orthogonal. Letting
            <span class="math inline">\(e_i= P_{i,k} a_k\)</span>, we
            see that <span class="math inline">\(e_i \cdot e_j = P_{i,k}
            P_{j,\ell} a_k \cdot a_\ell = P_{i,k} A_{k,\ell}
            (P^T)_{\ell,j} = D_{i,j}\)</span>. Therefore, these vectors
            obey <span class="math inline">\(e_i e_j = -e_j e_i\)</span>
            for <span class="math inline">\(i \neq j\)</span>. Finally,
            since <span class="math inline">\(e_i = P_{i,k} a_k \implies
            a_k = P_{i,k} e_i\)</span>: <span class="math display">\[
            a_1 \wedge \ldots \wedge a_r = \frac{1}{r!}\sum_{\sigma \in
            \mathbb{S}_r} (-1)^\sigma P_{i_1,\sigma(1)}
            P_{i_2,\sigma(2)} \ldots P_{i_r,\sigma(r)} e_{i_1} e_{i_2}
            \ldots e_{i_r}
            \]</span> Note that we have the restriction <span
            class="math inline">\(i_1 \neq i_2 \neq \ldots \neq
            i_r\)</span> due to the antisymmeterization of the sum.
            Therefore, we can rewrite as: <span
            class="math display">\[\begin{align*}
            a_1 \wedge \ldots \wedge a_r &amp;=
            \frac{1}{r!}\sum_{\rho,\sigma \in \mathbb{S}_r} (-1)^\sigma
            P_{\rho(1),\sigma(1)} P_{\rho(2),\sigma(2)} \ldots
            P_{\rho(r),\sigma(r)} e_{\rho(1)} e_{\rho(2)} \ldots
            e_{\rho(r)} \\
            &amp;= \frac{1}{r!}\sum_{\rho,\sigma \in \mathbb{S}_r}
            (-1)^{\rho^{-1}}(-1)^\sigma P_{1,\sigma(\rho^{-1}(1))}
            P_{2,\sigma(\rho^{-1}(2))} \ldots P_{r,\sigma(\rho^{-1}(r))}
            e_{1} e_{2} \ldots e_{r} \\
            &amp;= \sum_{\alpha \in \mathbb{S}_r} (-1)^{\alpha}
            P_{1,\alpha(1)} P_{2,\alpha(2)} \ldots P_{r,\alpha(r)} e_{1}
            e_{2} \ldots e_{r} \\
            &amp;= \det(P) e_1 \ldots e_r
            \end{align*}\]</span> In the second line, the factor <span
            class="math inline">\((-1)^{\rho^{-1}}\)</span> comes from
            unshuffling <span class="math inline">\(e_{\rho(1)} \ldots
            e_{\rho(r)} \rightarrow e_1 \ldots e_r\)</span>, and in the
            third line, we use the fact that for any function <span
            class="math inline">\(f\)</span> that depends only on <span
            class="math inline">\(\sigma \circ \rho^{-1}\)</span>: <span
            class="math inline">\(\sum_{\rho, \sigma \in \mathbb{S}_r}
            f(\sigma \circ \rho^{-1}) = r! \sum_{\alpha \in
            \mathbb{S}_r} f(\alpha)\)</span>, where <span
            class="math inline">\(\alpha\)</span> plays the role of
            <span class="math inline">\(\sigma \circ \rho^{-1}\)</span>.
            Now, observe that <span class="math inline">\(\det(P)= \pm
            1\)</span>, and in the case where <span
            class="math inline">\(\det(P)=-1\)</span>, we can simply
            reorder <span class="math inline">\(e_1, \ldots,e_r\)</span>
            to get rid of the negative sign.</p>
            </div>
            <p>In general, multivectors can be comprised of elements
            with different grades. For a set of orthogonal vectors, we
            say that <span class="math inline">\(e_i\)</span> has grade
            1, <span class="math inline">\(e_i e_j\)</span> (for <span
            class="math inline">\(i \neq j\)</span>) has grade 2, and so
            on. We define <span
            class="math inline">\(\expval{\cdot}_r\)</span> to be the
            component of a multivector with grade <span
            class="math inline">\(r\)</span>, so that in general a
            multivector <span class="math inline">\(A\)</span> in a
            geometric algebra <span
            class="math inline">\(\mathcal{G}_n\)</span> (whose
            underlying vector space has dimension <span
            class="math inline">\(n\)</span>) can be written <span
            class="math inline">\(A=\sum_{r=0}^n \expval{A}_r\)</span>.
            A multivector that satisfies <span
            class="math inline">\(\expval{A}_r=A\)</span> (for some
            <span class="math inline">\(r\)</span>) is called
            homogenous.</p>
            <p>We denote the subspace of <span
            class="math inline">\(\mathcal{G}_n\)</span> of grade <span
            class="math inline">\(r\)</span> as <span
            class="math inline">\(\mathcal{G}_n^r\)</span>. The
            dimensionality of <span
            class="math inline">\(\mathcal{G}_n^r\)</span> is <span
            class="math inline">\(\binom{n}{r}\)</span>, because the
            basis of <span
            class="math inline">\(\mathcal{G}_n^r\)</span> can be formed
            by choosing <span class="math inline">\(r\)</span> items
            from the <span class="math inline">\(n\)</span> basis
            vectors.<span
            class="sidenote-wrapper"><label for="sn-0" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-0" class="margin-toggle"/><span
            class="sidenote">It is important to note that not every
            multivector in <span
            class="math inline">\(\mathcal{G}_n^r\)</span> is a blade.
            The simplest nontrivial example is <span
            class="math inline">\(e_1 e_2 + e_3 e_4\)</span> in <span
            class="math inline">\(\mathcal{G}_n^4\)</span> – there is
            simply no way to write this as a blade because <span
            class="math inline">\({e_1,e_2}\)</span> and <span
            class="math inline">\({e_3,e_4}\)</span> are orthogonal to
            each other.<br />
            <br />
            </span></span> The overall dimensionality is therefore <span
            class="math inline">\(\sum_{r=0}^n
            \binom{n}{r}=2^n\)</span>.</p>
            <h2 data-number="1.1"
            id="properties-of-the-geometric-product"><span
            class="header-section-number">1.1</span> Properties of the
            Geometric Product</h2>
            <p>We now study the behavior of <span
            class="math inline">\(a B_r\)</span>, where <span
            class="math inline">\(a\)</span> is some vector and <span
            class="math inline">\(B_r\)</span> is a homogenous
            multivector of grade <span class="math inline">\(r\)</span>.
            More specifically, we will show that we can define <span
            class="math inline">\(a \cdot B_r\)</span> and <span
            class="math inline">\(a \wedge B_r\)</span> in terms of
            <span class="math inline">\(aB_r\)</span> and <span
            class="math inline">\(B_r a\)</span> in a way that is
            similar to the original definition for <span
            class="math inline">\(\cdot\)</span> and <span
            class="math inline">\(\wedge\)</span> between two ordinary
            vectors.</p>
            <div id="dot" class="statement theorem plain">
            <p><span class="statement-heading"><span
            class="statement-label">Theorem 2</span>.</span><span
            class="statement-spah"> </span>For any <span
            class="math inline">\(a \in \mathcal{G}_n^1\)</span> and
            <span class="math inline">\(B_r \in
            \mathcal{G}_n^r\)</span>, <span class="math inline">\(\qty(a
            B_r - (-1)^r B_r a)\)</span> is a homogenous multivector
            with grade <span class="math inline">\(r-1\)</span>. This
            motivates the definition <span id="eq:dot"><span
            class="math display">\[
            a \cdot B_r \coloneqq \frac{1}{2} (aB_r - (-1)^r B_r),
            \tag{1}\]</span></span> since now <span
            class="math inline">\(\cdot\)</span> lowers grade by <span
            class="math inline">\(1\)</span>.</p>
            </div>
            <div class="statement proof proof unnumbered">
            <p><span class="statement-heading"><span
            class="statement-label">Proof</span>.</span><span
            class="statement-spah"> </span>We assume <span
            class="math inline">\(B_r\)</span> is a blade, since all of
            the above statements are linear in <span
            class="math inline">\(B_r\)</span>. That is, it suffices to
            show that the above statement is true for <span
            class="math inline">\(B_r=e_1 e_2 \ldots e_r\)</span>, for
            any choice of orthogonal vectors <span
            class="math inline">\(\qty{e_1,\ldots,e_r}\)</span>. We
            repeatedly apply <span class="math inline">\(ab = 2a \cdot b
            - ba\)</span>. Observe that <span class="math inline">\(aB_r
            = 2 (a \cdot e_1) e_2 \ldots e_r - e_1 a e_2 \ldots
            e_r\)</span>. We can repeatedly do this, shifting <span
            class="math inline">\(a\)</span> further back in the chain,
            to get: <span class="math display">\[
            aB_r = 2 \sum_{k=1}^r (-1)^{k+1} (a \cdot e_k) (e_1 \ldots
            \check{e}_k \ldots e_r) + (-1)^r B_r a,
            \]</span> where <span
            class="math inline">\(\check{e}_k\)</span> denotes the fact
            that <span class="math inline">\(e_k\)</span> is omitted
            from the product (i.e. <span class="math inline">\(e_1
            \check{e}_2 e_3 = e_1 e_3\)</span>). A simple rearrangement
            gives: <span class="math display">\[
            \frac{1}{2} \qty(aB_r - (-1)^r B_r a) = \sum_{k=1}^r
            (-1)^{k+1} (a \cdot e_k) (e_1 \ldots \check{e}_k \ldots e_r)
            \]</span> Note that in the sum, <span
            class="math inline">\(e_1 \ldots \check{e}_k \ldots
            e_r\)</span> is grade <span
            class="math inline">\(r-1\)</span>. So, <span
            class="math inline">\(\frac{1}{2} \qty(aB_r - (-1)^r B_r
            a)\)</span> is a linear combination of blades, each of which
            are grade <span class="math inline">\(r-1\)</span> – so it
            is on the whole a homogenous multivector of grade <span
            class="math inline">\(r-1\)</span>.</p>
            </div>
            <p>A similar result holds for the wedge product <span
            class="math inline">\(\wedge\)</span>.</p>
            <div id="wedge" class="statement theorem plain">
            <p><span class="statement-heading"><span
            class="statement-label">Theorem 3</span>.</span><span
            class="statement-spah"> </span>For any blade <span
            class="math inline">\(B_r = b_1 \wedge \ldots \wedge
            b_r\)</span> and any vector <span
            class="math inline">\(a\)</span>: <span
            class="math display">\[
            a \wedge b_1 \wedge \ldots \wedge b_r = \frac{1}{2}\qty(a
            B_r + (-1)^r B_r a)
            \]</span></p>
            </div>
            <div class="statement proof proof unnumbered">
            <p><span class="statement-heading"><span
            class="statement-label">Proof</span>.</span><span
            class="statement-spah"> </span>Let <span
            class="math inline">\(e_1, \ldots e_r\)</span> be an
            orthogonalization of <span class="math inline">\(b_1, \ldots
            b_r\)</span> using the same technique as <a
            href="#blade-product" title="Lemma 1">Lemma 1</a>, such that
            <span class="math inline">\(b_1 \wedge \ldots \wedge b_r =
            e_1 \ldots e_r\)</span>. Then, let <span
            class="math inline">\(a_\perp = a - \sum_{k=1}^r \beta_k
            e_k\)</span>, where: <span class="math display">\[
            \beta_k = \begin{cases}
            \frac{a \cdot e_k}{(e_k \cdot e_k)^2} &amp; \qq{if $e_k
            \cdot e_k \neq 0$} \\
            0 &amp;\qq{otherwise}
            \end{cases}
            \]</span> Letting <span class="math inline">\(a_\parallel =
            \sum_{k=1}^r \beta_k e_k\)</span>, we can write <span
            class="math inline">\(a = a_\parallel + a_\perp\)</span>,
            and it is now simple to see that <span
            class="math inline">\(a_\perp \cdot e_k = 0\)</span> for all
            <span class="math inline">\(k=1,\ldots,r\)</span>.
            Furthermore, since each of the <span
            class="math inline">\(e_k\)</span> are merely linear
            combinations of <span class="math inline">\(b_k\)</span>,
            <span class="math inline">\(a_\perp \cdot b_k=0\)</span> for
            all <span class="math inline">\(k=1,\ldots,r\)</span> as
            well. Therefore, <span class="math inline">\(a \wedge b_1
            \wedge \ldots \wedge b_r=a_\perp \wedge b_1 \wedge \ldots
            \wedge b_r\)</span>.</p>
            <p>Now, observe that: <span
            class="math display">\[\begin{align*}
            a_\parallel B_r + (-1)^r B_r a_\parallel = \sum_{k=1}^r
            \beta_k \qty((-1)^{k+1}(e_k)^2 e_1 \ldots \check{e}_k \ldots
            e_r + (-1)^r (-1)^{r-k} e_1 \ldots \check{e}_k \ldots e_r
            (e_k)^2) \\
            &amp;= 0
            \end{align*}\]</span> Therefore, using the crucial fact that
            <span class="math inline">\(a_\perp b_k = -b_k
            a_\perp\)</span>: <span
            class="math display">\[\begin{align*}
            a B_r + (-1)^r B_r a &amp;= a_\perp B_r + (-1)^r B_r a_\perp
            \\
            &amp;= \frac{1}{r!}\sum_{\sigma \in \mathbb{S}_r}
            (-1)^{\sigma}\qty(a_\perp b_{\sigma(1)} \ldots b_{\sigma(r)}
            + (-1)^r b_{\sigma(1)} \ldots b_{\sigma(r)} a_\perp) \\
            &amp;= \frac{2}{r!} \sum_{\sigma \in \mathbb{S}_r}
            (-1)^\sigma a_\perp b_{\sigma(1)} \ldots b_{\sigma(r)} \\
            &amp;= \frac{2}{(r+1)!} \sum_{k=1}^{r+1} \sum_{\sigma \in
            \mathbb{S}_r} (-1)^\sigma a_\perp b_{\sigma(1)} \ldots
            b_{\sigma(r)}
            \end{align*}\]</span> Now, observe that we are free to
            scramble <span class="math inline">\(a_\perp\)</span>
            somewhere into the <span class="math inline">\(k\)</span>th
            position of <span class="math inline">\(b_{\sigma(1)} \ldots
            b_{\sigma(r)}\)</span> – that is, <span
            class="math inline">\(a_\perp b_{\sigma(1)} \ldots
            b_{\sigma(r)}=(-1)^k b_{\sigma(1)} \ldots b_{\sigma(k-1)}
            a_\perp b_{\sigma(k)} \ldots b_{\sigma(r)}\)</span>. But
            then, viewing <span class="math inline">\(a_\perp\)</span>
            as the first element of the set <span
            class="math inline">\(S = [a_\perp, b_1, \ldots,
            b_r]\)</span>, so that we identify <span
            class="math inline">\(b_0 = a_\perp\)</span> and <span
            class="math inline">\(S \cong [0, \ldots, r]\)</span>, we
            see that the permutation that sends <span
            class="math inline">\(S\)</span> to <span
            class="math inline">\([b_{\sigma(1)},\ldots,b_{\sigma(k-1)},a_\perp,b_{\sigma(k)},\ldots,b_{\sigma(r)}]
            \cong
            [\sigma(1),\ldots,\sigma(k-1),0,\sigma(k),\ldots,\sigma(r)]\)</span>
            has parity <span class="math inline">\((-1)^k
            (-1)^\sigma\)</span>! Therefore, the double sum over <span
            class="math inline">\(\sum_{k=1}^{r+1} \sum_{\sigma \in
            \mathbb{S}_r}\)</span> can be rewritten as a sum over
            permutations mapping <span
            class="math inline">\([0,\ldots,r]\)</span> onto itself –
            that is, <span
            class="math inline">\(\mathbb{S}_{r+1}\)</span>. We are then
            left with: <span class="math display">\[\begin{align*}
            a B_r + (-1)^r B_r a &amp;= \frac{2}{(r+1)!} \sum_{\sigma
            \in \mathbb{S}_{r+1}} b_{\sigma(0)} \ldots b_{\sigma(r)} \\
            &amp;= 2 a \wedge b_1 \wedge \ldots \wedge b_r,
            \end{align*}\]</span> as required.</p>
            </div>
            <div class="statement corollary plain">
            <p><span class="statement-heading"><span
            class="statement-label">Corollary 1</span>.</span><span
            class="statement-spah"> </span>For any multivector <span
            class="math inline">\(B_r \in \mathcal{G}_n^r\)</span>, let
            <span class="math inline">\(a \wedge B_r\)</span> be defined
            by: <span id="eq:wedge"><span class="math display">\[
            a \wedge B_r \coloneqq \frac{1}{2} (aB_r + (-1)^r B_r),
            \tag{2}\]</span></span> Then, <span class="math inline">\(a
            \wedge B_r\)</span> is always a homogenous multivector of
            grade <span class="math inline">\(r+1\)</span>. That is,
            <span class="math inline">\(\wedge\)</span> raises grade by
            <span class="math inline">\(1\)</span>.</p>
            </div>
            <div class="statement proof proof unnumbered">
            <p><span class="statement-heading"><span
            class="statement-label">Proof</span>.</span><span
            class="statement-spah"> </span>This follows simply by
            decomposing <span class="math inline">\(B_r\)</span> into a
            linear combination of blades and applying <a href="#wedge"
            title="Theorem 3">Theorem 3</a> to each blade (observing
            that <span class="math inline">\(a \wedge B_r\)</span> is
            bilinear)</p>
            </div>
            <p>It follows trivially from the definitions in <a
            href="#eq:dot">Equation 1</a> and <a
            href="#eq:wedge">Equation 2</a> that <span
            class="math inline">\(a B_r=a \cdot B_r + a \wedge
            B_r\)</span>, which says that the product <span
            class="math inline">\(aB_r\)</span> is a sum of homogenous
            multivectors with grade <span class="math inline">\(r \pm
            1\)</span>. This can be generalized for a general
            multivector <span class="math inline">\(A_s\)</span>. Since
            <span class="math inline">\(A_s\)</span> can be written as a
            linear combination of blades, and each blade can be written
            as a product of anticommuting (orthogonal) vectors, <span
            class="math inline">\(A_s B_r\)</span> is composed of
            multivectors with grades <span
            class="math inline">\(\abs{r-s}, \abs{r-s}+2, \ldots,
            r+s\)</span>.</p>
            <h1 class="unnumbered" id="bibliography">References</h1>
            <div id="refs"
            class="references csl-bib-body hanging-indent"
            role="doc-bibliography">
            <div id="ref-doran2007" class="csl-entry"
            role="doc-biblioentry">
            Doran, Chris, and A. N. Lasenby. 2007. <em>Geometric Algebra
            for Physicists</em>. 1st ed. Cambridge ; New York: Cambridge
            University Press.
            </div>
            </div>
      
      <div>
                <hr style="margin: 1em 0.2em 1em 60%" />

        <p class="date">Last modified: June 28, 2022</p>
              </div>
    </div>

  </div>

</body>

</html>